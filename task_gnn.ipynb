{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "i4WcGtt1SP88",
        "V_k5VYXQSUwp",
        "T8oB-KlJSaat",
        "jNsToorfSgS0",
        "i-FXQsBGSk0K"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4WcGtt1SP88"
      },
      "source": [
        "## Installing PyTorch Geometric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3r2f7FITB71",
        "outputId": "bdab8b84-2096-4e4d-ceff-81c8f1321c7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check CUDA Version\n",
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "\n",
        "# Install Pytorch Geometric\n",
        "!pip install -q torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
        "!pip install -q torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.8\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch-scatter==latest+cu101 (from versions: 0.3.0, 1.0.2, 1.0.3, 1.0.4, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.3.0, 1.3.1, 1.3.2, 1.4.0, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.1.0, 2.1.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch-scatter==latest+cu101\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch-sparse==latest+cu101 (from versions: 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.5.1, 0.6.0, 0.6.1, 0.6.3, 0.6.4, 0.6.5, 0.6.6, 0.6.7, 0.6.8, 0.6.9, 0.6.10, 0.6.11, 0.6.12, 0.6.13, 0.6.14, 0.6.15, 0.6.16, 0.6.17)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch-sparse==latest+cu101\u001b[0m\u001b[31m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_k5VYXQSUwp"
      },
      "source": [
        "## Knowledge Graphs and Node Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEdJScZr_a5H"
      },
      "source": [
        "There are two special properties we are dealing with in this example:\n",
        "1. We have one large graph and not many individual graphs (like molecules)\n",
        "2. We infere on unlabeled nodes in this large graph and hence perform node-level predictions --> We have to use different nodes of the graph depending on what we want to do"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8oB-KlJSaat"
      },
      "source": [
        "## Dataset Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnREblkZTe02"
      },
      "source": [
        "There exists different datasets in PyTorch Geometric that can be used to perform Node Classification on large Knowledge Graphs e.g. Karate Network or Cora. We will use Cora to showcase the use of binary masks for node-level predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITnwYh-a3Hyj"
      },
      "source": [
        "#### What is the Cora Dataset?\n",
        "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.\n",
        "\n",
        "- Nodes = Publications (Papers, Books ...)\n",
        "- Edges = Citations\n",
        "- Node Features = word vectors\n",
        "- 7 Labels = Pubilcation type e.g. Neural_Networks, Rule_Learning, Reinforcement_Learning, \tProbabilistic_Methods...\n",
        "\n",
        "We normalize the features using torch geometric's transform functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s96RfvA1z5xQ",
        "outputId": "b5496d4b-9186-447d-d10c-d9f3823b738c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvzKbxnI0vsN"
      },
      "source": [
        "PyTorch Geometric provides different functions to investigate the dataset (e.g. node degrees, self-loops ect.) - You can find more of them in the documentation or in [this notebook](https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=eqWR0j_kIx67)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxlhrODKz_W5",
        "outputId": "1d5baa40-c41e-4056-b4f1-1da65c1b1541",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get some basic info about the dataset\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "print(50*'=')\n",
        "\n",
        "# There is only one graph in the dataset, use it as new data object\n",
        "data = dataset[0]\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(data)\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of graphs: 1\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n",
            "==================================================\n",
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
            "Number of nodes: 2708\n",
            "Number of edges: 10556\n",
            "Number of training nodes: 140\n",
            "Training node label rate: 0.05\n",
            "Is undirected: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHJgiYySxqwL"
      },
      "source": [
        "Observations:\n",
        "- We only have a relatively small set of training nodes (20 nodes per class)\n",
        "- There are binary test, train and validation masks of the size #nodes (they tell use which node can be used for which task)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhuqocpv2bwd",
        "outputId": "f140ad1c-8251-4dec-bad2-9086a00a387a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(data.x.shape) # [No. Nodes x Features]\n",
        "\n",
        "# Print some of the normalized word counts of the first datapoint\n",
        "data.x[0][:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2708, 1433])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.1111, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmmVhxn_Any8"
      },
      "source": [
        "Why do we even use the graph structure - aren't the features enough?\n",
        "\n",
        "- Apparently, simple MLP models perform a lot worse than GNNs on this type of task, as the citation information is crucial for a correct classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2MMb7HFycnG"
      },
      "source": [
        "How do the labels look like?\n",
        "- They are encoded as numeric value between 0-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EsnHlkX7cZs",
        "outputId": "3d544eb8-73b6-423f-86fc-791bb4ff4561",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 4,  ..., 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPHFpD-ahP88"
      },
      "source": [
        "Example for the binary masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt7M5rt_hPfZ",
        "outputId": "ff2855d9-f402-40c0-d9eb-08fe5f6fbd30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(data.test_mask) == data.num_nodes)\n",
        "data.test_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False,  ...,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6ydlu3-jjqV"
      },
      "source": [
        "Example for the edge connections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAqU7XerjnKx",
        "outputId": "5c312923-5098-4f80-f661-4f25102f23f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.edge_index.t()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,  633],\n",
              "        [   0, 1862],\n",
              "        [   0, 2582],\n",
              "        ...,\n",
              "        [2707,  598],\n",
              "        [2707, 1473],\n",
              "        [2707, 2706]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNsToorfSgS0"
      },
      "source": [
        "## Graph Neural Network for Node Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcffG3rQy79R",
        "outputId": "79969126-5dde-45b3-efe1-09a476b45c75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv #GATConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # Initialize the layers\n",
        "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.out = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First Message Passing Layer (Transformation)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Second Message Passing Layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Output layer\n",
        "        x = F.softmax(self.out(x), dim=1)\n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=16)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(1433, 16)\n",
            "  (conv2): GCNConv(16, 16)\n",
            "  (out): Linear(in_features=16, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e5Tl6J2j5S-"
      },
      "source": [
        "Observations:\n",
        "- Dropout is only applied in the training step, but not for predictions\n",
        "- We have 2 Message Passing Layers and one Linear output layer\n",
        "- We use the softmax function for the classification problem\n",
        "- The output of the model are 7 probabilities, one for each class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-FXQsBGSk0K"
      },
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY77lILlzPXO",
        "outputId": "9e12d7ae-b0af-4b6a-b670-f8128ca3c49f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Initialize model\n",
        "model = GCN(hidden_channels=16)\n",
        "\n",
        "# Use GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "# Initialize Optimizer\n",
        "learning_rate = 0.01\n",
        "decay = 5e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr=learning_rate,\n",
        "                             weight_decay=decay)\n",
        "# Define loss function (CrossEntropyLoss for Classification Problems with\n",
        "# probability distributions)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      # Use all data as input, because all nodes have node features\n",
        "      out = model(data.x, data.edge_index)\n",
        "      # Only use nodes with labels available for loss calculation --> mask\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      return loss\n",
        "\n",
        "def test():\n",
        "      model.eval()\n",
        "      out = model(data.x, data.edge_index)\n",
        "      # Use the class with highest probability.\n",
        "      pred = out.argmax(dim=1)\n",
        "      # Check against ground-truth labels.\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
        "      # Derive ratio of correct predictions.\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
        "      return test_acc\n",
        "\n",
        "losses = []\n",
        "for epoch in range(0, 1001):\n",
        "    loss = train()\n",
        "    losses.append(loss)\n",
        "    if epoch % 100 == 0:\n",
        "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 1.9461\n",
            "Epoch: 100, Loss: 1.7376\n",
            "Epoch: 200, Loss: 1.5091\n",
            "Epoch: 300, Loss: 1.4761\n",
            "Epoch: 400, Loss: 1.4391\n",
            "Epoch: 500, Loss: 1.3843\n",
            "Epoch: 600, Loss: 1.3577\n",
            "Epoch: 700, Loss: 1.3699\n",
            "Epoch: 800, Loss: 1.3572\n",
            "Epoch: 900, Loss: 1.3668\n",
            "Epoch: 1000, Loss: 1.3654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zsXPVNEly8I"
      },
      "source": [
        "Visualize the training loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-c68XAAl5c-"
      },
      "source": [
        "Calculate test metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9oH4zpQzS0S",
        "outputId": "e7a6d6a8-a5b1-4651-9ede-c7adefba210d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_acc = test()\n",
        "print(f'Test Accuracy: {test_acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S3shZpQrYGm",
        "outputId": "0a510f9c-f708-4732-fc61-9a99f319a107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "sample = 9\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "print(model(data.x, data.edge_index).shape)\n",
        "pred = model(data.x, data.edge_index)\n",
        "sns.barplot(x=np.array(range(7)), y=pred[sample].detach().cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2708, 7])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdSdcLrS0x2H"
      },
      "source": [
        "### Visualizing the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYgHw6M9mIxG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "def plt2arr(fig):\n",
        "    rgb_str = fig.canvas.tostring_rgb()\n",
        "    (w,h) = fig.canvas.get_width_height()\n",
        "    rgba_arr = np.fromstring(rgb_str, dtype=np.uint8, sep='').reshape((w,h,-1))\n",
        "    return rgba_arr\n",
        "\n",
        "\n",
        "def visualize(h, color, epoch):\n",
        "    fig = plt.figure(figsize=(5,5), frameon=False)\n",
        "    fig.suptitle(f'Epoch = {epoch}')\n",
        "    # Fit TSNE with 2 components\n",
        "    z = TSNE(n_components=2).fit_transform(out.detach().cpu().numpy())\n",
        "\n",
        "    # Create scatterplot from embeddings\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.scatter(z[:, 0],\n",
        "                z[:, 1],\n",
        "                s=70,\n",
        "                c=color.detach().cpu().numpy(),\n",
        "                cmap=\"Set2\")\n",
        "    fig.canvas.draw()\n",
        "\n",
        "    # Convert to numpy\n",
        "    return plt2arr(fig)\n",
        "\n",
        "\n",
        "# Reset the previously trained model weights\n",
        "for layer in model.children():\n",
        "   if hasattr(layer, 'reset_parameters'):\n",
        "       layer.reset_parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmJFwjEDzZW1"
      },
      "source": [
        "# Ignore deprecation warnings here\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Train the model and save visualizations\n",
        "images = []\n",
        "for epoch in range(0, 2000):\n",
        "    loss = train()\n",
        "    if epoch % 50 == 0:\n",
        "      out = model(data.x, data.edge_index)\n",
        "      images.append(visualize(out, color=data.y, epoch=epoch))\n",
        "print(\"TSNE Visualization finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}